{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30997516",
   "metadata": {},
   "source": [
    "**IMPORTACIONES NECESARIAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report  \n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_VGG16\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as preprocess_VGG19\n",
    "\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input as preprocess_Xception\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as preprocess_ResNet50V2\n",
    "\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as preprocess_ResNet101_152\n",
    "\n",
    "from tensorflow.keras.applications import ResNet152\n",
    "\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_InceptionV3\n",
    "\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input as preprocess_InceptionResNetV2\n",
    "\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as preprocess_MobileNet\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as preprocess_DenseNet121\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as preprocess_DenseNet201\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ff18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 'rgb' \n",
    "batch = 16\n",
    "dic_escala = {VGG16:224,VGG19:224,Xception:299,ResNet50V2:224,ResNet101:224,ResNet152:224,InceptionResNetV2:299,MobileNet:224,DenseNet121:224,DenseNet201:224,EfficientNetB0:224,InceptionV3:299}\n",
    "dic_preprocesado = {VGG16:preprocess_VGG16,\n",
    "                VGG19:preprocess_VGG19,\n",
    "                Xception:preprocess_Xception,\n",
    "                ResNet50V2:preprocess_ResNet50V2,\n",
    "                ResNet101:preprocess_ResNet101_152,\n",
    "                ResNet152:preprocess_ResNet101_152,\n",
    "                InceptionResNetV2:preprocess_InceptionResNetV2,\n",
    "                MobileNet:preprocess_MobileNet,\n",
    "                DenseNet121:preprocess_DenseNet121,\n",
    "                DenseNet201:preprocess_DenseNet201,\n",
    "                EfficientNetB0:preprocess_EfficientNetB0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f04c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos(path1, path2, escala, color = color):\n",
    "    \n",
    "    EMD = os.listdir(path1)\n",
    "    NO_EMD = os.listdir(path2)\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i in EMD:   \n",
    "        image=tf.keras.preprocessing.image.load_img(path1+'/'+i, color_mode= color, \n",
    "        target_size= (escala, escala))\n",
    "        image=np.array(image)\n",
    "        data.append(image)\n",
    "        labels.append(1)\n",
    "    for i in NO_EMD:   \n",
    "        image=tf.keras.preprocessing.image.load_img(path2+'/'+i, color_mode= color, \n",
    "        target_size= (escala, escala))\n",
    "        image=np.array(image)\n",
    "        data.append(image)\n",
    "        labels.append(0)\n",
    "        \n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f10de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transferLearning_classweight_holdout(inp,proc,red):\n",
    "    \n",
    "    #CARGA DE DATOS\n",
    "    \n",
    "    escala = dic_escala[red]\n",
    "    \n",
    "    if inp==False:\n",
    "        if proc==False:\n",
    "            ruta_general='Datos base EMD'\n",
    "        else:\n",
    "            ruta_general='Datos base preprocesados EMD'\n",
    "    else:\n",
    "        if proc==False:\n",
    "            ruta_general='Datos base INP EMD'\n",
    "        else:\n",
    "            ruta_general='Datos preprocesados base INP EMD'\n",
    "    \n",
    "    dataset_iphone = cargar_datos(ruta_general+'/iPhone/EMD', ruta_general+'/iPhone/NO EMD', escala)\n",
    "    dataset_samsung = cargar_datos(ruta_general+'/Samsung/EMD', ruta_general+'/Samsung/NO EMD', escala)\n",
    "    dataset_oct = cargar_datos(ruta_general+'/OCT/EMD', ruta_general+'/OCT/NO EMD', escala)\n",
    "    \n",
    "    print('___________________________________________________________________________________')\n",
    "    print('TEST: iPHONE')\n",
    "    print('___________________________________________________________________________________')\n",
    "    print(f'La red empleada es {red} por lo que las imágenes sean reescalado a {escala}x{escala}')\n",
    "    print(f'Las imágenes están es {color}, están inpaintadas {inp}, están preprocesadas {inp}')\n",
    "    print('___________________________________________________________________________________')\n",
    "\n",
    "    \n",
    "    train_ds = np.concatenate((dataset_oct[0],dataset_samsung[0]))\n",
    "    train_labels = np.concatenate((dataset_oct[1],dataset_samsung[1]))\n",
    " \n",
    "    test_ds = dataset_iphone[0]\n",
    "    test_labels = dataset_iphone[1]\n",
    "    \n",
    "    #PREPROCESADO DE LOS DATOS\n",
    "    \n",
    "    \n",
    "    train_ds = dic_preprocesado[red](train_ds) \n",
    "    test_ds = dic_preprocesado[red](test_ds)\n",
    "    \n",
    "    train_labels_categorical = to_categorical(train_labels, num_classes=2)\n",
    "    test_labels_categorical = to_categorical(test_labels, num_classes=2)\n",
    "    \n",
    "    #IMPORTACIÓN MODELO TRANSFER LEARNING\n",
    "    \n",
    "    base_model = red(weights=\"imagenet\", include_top=False, input_shape=train_ds[0].shape)\n",
    "    base_model.trainable = False ## Not trainable weights\n",
    "    \n",
    "    #FINE TUNNING\n",
    "    \n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer_1 = layers.Dense(50, activation='relu')\n",
    "    dense_layer_2 = layers.Dense(20, activation='relu')\n",
    "    prediction_layer = layers.Dense(2, activation='softmax') #1 / sigmoid\n",
    "\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer_1,\n",
    "        dense_layer_2,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    \n",
    "    #COMPENSADOR DE PESOS\n",
    "    \n",
    "    classes = np.unique(train_labels)\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=classes, y=train_labels)\n",
    "    dic_class_weights = {0:class_weights[0], 1:class_weights[1]}\n",
    "    \n",
    "    #ENTRENAMIENTO\n",
    "    \n",
    "    model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy', #binary_crossentropy\n",
    "    metrics=['accuracy'],)\n",
    "\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', patience=20,  restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(train_ds, train_labels_categorical, epochs=200, validation_split=0.2, batch_size=32, callbacks=[es], class_weight=dic_class_weights)\n",
    "    \n",
    "    #MÉTRICAS DE EVALUACIÓN\n",
    "    \n",
    "    print('Las métricas de evaluación obtenidas para iPhone son:')\n",
    "    \n",
    "    score_test = model.evaluate(x=test_ds, y=test_labels_categorical, verbose = 0)\n",
    "    print(\"Test loss:\", score_test[0])\n",
    "    print(\"Test accuracy:\", score_test[1])\n",
    "    \n",
    "    predictions = model.predict(test_ds)\n",
    "    pred = list(map(lambda x: list(x).index(max(x)),predictions))\n",
    "    \n",
    "    matrix = confusion_matrix(test_labels, pred)\n",
    "    print(f\"Matriz de confusión en test con iPhone:\\n\\n{matrix}\\n\")\n",
    "    \n",
    "    f_score = f1_score(test_labels, pred, average = 'weighted')\n",
    "    print(f\"Valor de 'F1 score' en test con iPhone: {f_score}\\n\")\n",
    "    \n",
    "    auc_roc = roc_auc_score(test_labels, pred, multi_class = 'ovo')\n",
    "    print(f\"Valor de 'AUC' en test con iPhone: {auc_roc}\\n\")\n",
    "    \n",
    "    print('___________________________________________________________________________________')\n",
    "    print('TEST: Samsung')\n",
    "    print('___________________________________________________________________________________')\n",
    "    print(f'La red empleada es {red} por lo que las imágenes sean reescalado a {escala}x{escala}')\n",
    "    print(f'Las imágenes están es {color}, están inpaintadas {inp}, están preprocesadas {inp}')\n",
    "    print('___________________________________________________________________________________')\n",
    "    \n",
    "    train_ds = np.concatenate((dataset_oct[0],dataset_iphone[0]))\n",
    "    train_labels = np.concatenate((dataset_oct[1],dataset_iphone[1]))\n",
    " \n",
    "    test_ds = dataset_samsung[0]\n",
    "    test_labels = dataset_samsung[1]\n",
    "    \n",
    "    #PREPROCESADO DE LOS DATOS\n",
    "    \n",
    "    train_ds = dic_preprocesado[red](train_ds) \n",
    "    test_ds = dic_preprocesado[red](test_ds)\n",
    "    \n",
    "    train_labels_categorical = to_categorical(train_labels, num_classes=2)\n",
    "    test_labels_categorical = to_categorical(test_labels, num_classes=2)\n",
    "    \n",
    "    #IMPORTACIÓN MODELO TRANSFER LEARNING\n",
    "    \n",
    "    base_model = red(weights=\"imagenet\", include_top=False, input_shape=train_ds[0].shape)\n",
    "    base_model.trainable = False ## Not trainable weights\n",
    "    \n",
    "    #FINE TUNNING\n",
    "    \n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer_1 = layers.Dense(50, activation='relu')\n",
    "    dense_layer_2 = layers.Dense(20, activation='relu')\n",
    "    prediction_layer = layers.Dense(2, activation='softmax') #1 / sigmoid\n",
    "\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer_1,\n",
    "        dense_layer_2,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    \n",
    "    #COMPENSADOR DE PESOS\n",
    "    \n",
    "    classes = np.unique(train_labels)\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=classes, y=train_labels)\n",
    "    dic_class_weights = {0:class_weights[0], 1:class_weights[1]}\n",
    "    \n",
    "    #ENTRENAMIENTO\n",
    "    \n",
    "    model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy', #binary_crossentropy\n",
    "    metrics=['accuracy'],)\n",
    "\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', patience=20,  restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(train_ds, train_labels_categorical, epochs=200, validation_split=0.2, batch_size=32, callbacks=[es], class_weight=dic_class_weights)\n",
    "    \n",
    "    #MÉTRICAS DE EVALUACIÓN\n",
    "    \n",
    "    print('Las métricas de evaluación obtenidas para Samsung son:')\n",
    "    \n",
    "    score_test = model.evaluate(x=test_ds, y=test_labels_categorical, verbose = 0)\n",
    "    print(\"Test loss:\", score_test[0])\n",
    "    print(\"Test accuracy:\", score_test[1])\n",
    "    \n",
    "    predictions = model.predict(test_ds)\n",
    "    pred = list(map(lambda x: list(x).index(max(x)),predictions))\n",
    "    \n",
    "    matrix = confusion_matrix(test_labels, pred)\n",
    "    print(f\"Matriz de confusión en test con Samsung:\\n\\n{matrix}\\n\")\n",
    "    \n",
    "    f_score = f1_score(test_labels, pred, average = 'weighted')\n",
    "    print(f\"Valor de 'F1 score' en test con Samsung: {f_score}\\n\")\n",
    "    \n",
    "    auc_roc = roc_auc_score(test_labels, pred, multi_class = 'ovo')\n",
    "    print(f\"Valor de 'AUC' en test con Samsung: {auc_roc}\\n\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b266740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('___________________________________________________________________________________')\n",
    "print('SIN INPAINT SIN PREPROCESAMIENTO')\n",
    "print('___________________________________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe709c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in [VGG16, VGG19, Xception, ResNet50V2, ResNet101, ResNet152, InceptionV3, InceptionResNetV2, MobileNet, DenseNet121, DenseNet201, EfficientNetB0]:\n",
    "    transferLearning_classweight_holdout(False,False,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('___________________________________________________________________________________')\n",
    "print('SIN INPAINT CON PREPROCESAMIENTO')\n",
    "print('___________________________________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac6d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in [VGG16, VGG19, Xception, ResNet50V2, ResNet101, ResNet152, InceptionV3, InceptionResNetV2, MobileNet, DenseNet121, DenseNet201, EfficientNetB0]:\n",
    "    transferLearning_classweight_holdout(False,True,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eadc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('___________________________________________________________________________________')\n",
    "print('CON INPAINT SIN PREPROCESAMIENTO')\n",
    "print('___________________________________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc754622",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in [VGG16, VGG19, Xception, ResNet50V2, ResNet101, ResNet152, InceptionV3, InceptionResNetV2, MobileNet, DenseNet121, DenseNet201, EfficientNetB0]:\n",
    "    transferLearning_classweight_holdout(True,False,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604656c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('___________________________________________________________________________________')\n",
    "print('CON INPAINT CON PREPROCESAMIENTO')\n",
    "print('___________________________________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0fb353",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in [VGG16, VGG19, Xception, ResNet50V2, ResNet101, ResNet152, InceptionV3, InceptionResNetV2, MobileNet, DenseNet121, DenseNet201, EfficientNetB0]:\n",
    "    transferLearning_classweight_holdout(True,True,e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
