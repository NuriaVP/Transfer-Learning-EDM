{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f41162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report  \n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.applications import ResNet152\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.applications import EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec43620",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 'rgb' #'grayscale' o 'rgb'\n",
    "batch = 64\n",
    "escala = 752"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16afcde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_generator(gen1, gen2):\n",
    "    while True:\n",
    "        tupla1 = next(gen1)\n",
    "        tupla2 = next(gen2)\n",
    "        \n",
    "        array_img_1 = tupla1[0]\n",
    "        array_labels_1 = tupla1[1]\n",
    "        \n",
    "        array_img_2 = tupla2[0]\n",
    "        array_labels_2 = tupla2[1]\n",
    "        \n",
    "        arrays_img = np.concatenate((array_img_1,array_img_2))\n",
    "        arrays_labels = np.concatenate((array_labels_1,array_labels_2))\n",
    "        \n",
    "        yield(tuple((arrays_img,arrays_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51935ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transferLearning_classweight(test, red):\n",
    "    \n",
    "    #Definir el ImageDataGenerator de entrenamiento (reescalado 1./255 necesario y el tamaño de validación split requerido)    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        validation_split = 0.2\n",
    "    )\n",
    "    \n",
    "    #Definimos el generador que va a ir cargando las imágenes de Kaggle/Messidor (para train y para validation) \n",
    "    train_generator_1 = train_datagen.flow_from_directory(\n",
    "        directory = 'Datos preprocesados INP EMD/OCT',\n",
    "        target_size = (escala,escala),\n",
    "        color_mode = color,\n",
    "        class_mode='categorical',\n",
    "        batch_size = int(2*batch/5),#indicamos la proporción de imágenes del batch que queremos que correspondan a Kaggle (2/5 p. ej.)\n",
    "        seed = 42,\n",
    "        subset='training'\n",
    "    )\n",
    " \n",
    "    train_generator_2 = train_datagen.flow_from_directory(\n",
    "        directory = 'Datos preprocesados INP EMD/MESSIDOR',\n",
    "        target_size = (escala,escala),\n",
    "        color_mode = color,\n",
    "        class_mode='categorical',\n",
    "        batch_size = int(2*batch/5),#indicamos la proporción de imágenes del batch que queremos que correspondan a Kaggle (2/5 p. ej.)\n",
    "        seed = 42,\n",
    "        subset='training'\n",
    "    )\n",
    "    \n",
    "    val_generator_1 = train_datagen.flow_from_directory(\n",
    "        directory = 'Datos preprocesados INP EMD/OCT',\n",
    "        target_size = (escala,escala),\n",
    "        color_mode = color,\n",
    "        class_mode='categorical',\n",
    "        batch_size = int(2*batch/5),#indicamos la proporción de imágenes del batch que queremos que correspondan a Kaggle (3/4 p. ej.)\n",
    "        seed = 42,\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    val_generator_2 = train_datagen.flow_from_directory(\n",
    "        directory = 'Datos preprocesados INP EMD/MESSIDOR',\n",
    "        target_size = (escala,escala),\n",
    "        color_mode = color,\n",
    "        class_mode='categorical',\n",
    "        batch_size = int(2*batch/5),#indicamos la proporción de imágenes del batch que queremos que correspondan a Kaggle (3/4 p. ej.)\n",
    "        seed = 42,\n",
    "        subset='validation'\n",
    "    )\n",
    "    \n",
    "    #A continuación creamos el generador de train y validation con imágenes de Samsung/iPhone (según el parámetro pedido)\n",
    "    if test=='iphone':\n",
    "        train_generator_3 = train_datagen.flow_from_directory(\n",
    "            directory = 'Datos preprocesados INP EMD/Samsung',\n",
    "            target_size = (escala,escala),\n",
    "            color_mode = color,\n",
    "            class_mode='categorical',\n",
    "            batch_size = int(batch/5),#indicamos la proporción de imágenes del batch que queremos que correspondan a iphone (1/5 p. ej.)\n",
    "            seed = 42,\n",
    "            subset='training'\n",
    "        )\n",
    "\n",
    "        val_generator_3 = train_datagen.flow_from_directory(\n",
    "            directory = 'Datos preprocesados INP EMD/Samsung',\n",
    "            target_size = (escala,escala),\n",
    "            color_mode = color,\n",
    "            class_mode='categorical',\n",
    "            batch_size = int(batch/5),\n",
    "            seed = 42,\n",
    "            subset='validation'\n",
    "        )\n",
    "        \n",
    "    elif test=='samsung':\n",
    "        train_generator_3 = train_datagen.flow_from_directory(\n",
    "            directory = 'Datos preprocesados INP EMD/iPhone',\n",
    "            target_size = (escala,escala),\n",
    "            color_mode = color,\n",
    "            class_mode='categorical',\n",
    "            batch_size = int(batch/5),\n",
    "            seed = 42,\n",
    "            subset='training'\n",
    "        )\n",
    "\n",
    "        val_generator_3 = train_datagen.flow_from_directory(\n",
    "            directory = 'Datos preprocesados INP EMD/iPhone',\n",
    "            target_size = (escala,escala),\n",
    "            color_mode = color,\n",
    "            class_mode='categorical',\n",
    "            batch_size = int(batch/5),\n",
    "            seed = 42,\n",
    "            subset='validation'\n",
    "        )\n",
    "        \n",
    "    #Por último combinamos los generadores de train y validation creados\n",
    "    train_generator = combine_generator(train_generator_1, train_generator_2)\n",
    "    train_generator = combine_generator(train_generator, train_generator_3)\n",
    "    val_generator = combine_generator(val_generator_1,val_generator_2)\n",
    "    val_generator = combine_generator(val_generator,val_generator_3)\n",
    "    \n",
    "    #Definir el generador de test, según si el test es iPhone o Samsung\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    if test=='iphone':\n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "            directory = 'Datos preprocesados INP EMD/iPhone',\n",
    "            target_size = (escala,escala),\n",
    "            color_mode = color,\n",
    "            shuffle = False,\n",
    "            class_mode='categorical',\n",
    "            batch_size=1,\n",
    "            seed = 42\n",
    "        )\n",
    "        \n",
    "    elif test=='samsung':\n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "            directory = 'Datos preprocesados INP EMD/Samsung',\n",
    "            target_size = (escala,escala),\n",
    "            color_mode = color,\n",
    "            shuffle = False,\n",
    "            class_mode='categorical',\n",
    "            batch_size=1,\n",
    "            seed = 42\n",
    "        )\n",
    "    \n",
    "    #al usar ImageDataGenerator no se realiza conversión de las labels\n",
    "    #train_labels_categorical = to_categorical(train_labels, num_classes=5)\n",
    "    #test_labels_categorical = to_categorical(test_labels, num_classes=5)\n",
    "        \n",
    "    #Definir modelo de trasnfer learning\n",
    "    base_model = red(weights=None, include_top=False, input_shape=train_generator_1.image_shape)\n",
    "    base_model.load_weights('Pesos/' + str(red).split(' ')[1] + '.h5')\n",
    "    base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "    #Al usar ImageDataGenerator no se realiza preprocesamiento de los datos\n",
    "    #train_ds = preprocess_input(train_ds) \n",
    "    #test_ds = preprocess_input(test_ds)\n",
    "    \n",
    "    #Definir fine tunning\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer_1 = layers.Dense(1024, activation='relu')\n",
    "    dense_layer_2 = layers.Dense(512, activation='relu')\n",
    "    prediction_layer = layers.Dense(5, activation='softmax')\n",
    "\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer_1,\n",
    "        dense_layer_2,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    \n",
    "    #Definir compensador de pesos\n",
    "    classes = np.unique(np.concatenate((train_generator_1.classes,train_generator_2.classes)))\n",
    "    class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=classes, y=np.concatenate((train_generator_1.classes,train_generator_2.classes)))\n",
    "    dic_class_weights = {0:class_weights[0], 1:class_weights[1]}\n",
    "    \n",
    "    #Entrenar el modelo\n",
    "    model.compile(\n",
    "        optimizer='Ftrl',\n",
    "        loss='kl_divergence',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', patience=20,  restore_best_weights=True)\n",
    "\n",
    "    #ahora el .fit acepta también generators como x\n",
    "    history = model.fit(\n",
    "        x = train_generator,\n",
    "        batch_size=batch,\n",
    "        epochs=200,\n",
    "        callbacks=[es],\n",
    "        validation_data = val_generator,\n",
    "        class_weight = dic_class_weights\n",
    "    )\n",
    "    \n",
    "    #Métricas de evaluación\n",
    "    print('##########################################################################')\n",
    "    print(f'MÉTRICAS DE EVALUACIÓN\\n *Holdout\\n *ClassWeights\\n *Red: {red}\\n *Test: {test}')\n",
    "    print('##########################################################################')\n",
    "    score_test = model.evaluate(x = test_generator, verbose = 0)\n",
    "    print(\"Test loss:\", score_test[0])\n",
    "    print(\"Test accuracy:\", score_test[1])\n",
    "    \n",
    "    y_test = test_generator.classes\n",
    "    \n",
    "    predictions = model.predict(test_generator)\n",
    "    y_pred = list(map(lambda x: list(x).index(max(x)),predictions))\n",
    "\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Matriz de confusión del modelo:\\n\\n{matrix}\\n\")\n",
    "    \n",
    "    f_score = f1_score(y_true = y_test, y_pred = y_pred, average = 'weighted')\n",
    "    print(f\"Valor de 'F1 score' del modelo: {f_score}\\n\")\n",
    "    \n",
    "    auc_roc = roc_auc_score(y_true = y_test, y_score = predictions, multi_class = 'ovr')\n",
    "    print(f\"Valor de 'AUC' del modelo: {auc_roc}\\n\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258eabb7",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087bc827",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_vgg16 = transferLearning_classweight('iphone', VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_vgg16_bis = transferLearning_classweight('samsung', VGG16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b376557e",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_vgg19 = transferLearning_classweight('iphone', VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6331c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_vgg19_bis = transferLearning_classweight('samsung', VGG19)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
