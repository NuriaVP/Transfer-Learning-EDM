{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbcf5f02",
   "metadata": {},
   "source": [
    "# PRUEBA VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce20086",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/transfer-learning-with-vgg16-and-keras-50ea161580b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8405d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec00ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\usuario\\anaconda3\\lib\\site-packages (4.7.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.1.1)\n",
      "Requirement already satisfied: toml in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (4.64.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.11.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.3.0)\n",
      "Requirement already satisfied: dill in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.3.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.21.5)\n",
      "Requirement already satisfied: etils[epath] in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.9.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.27.1)\n",
      "Requirement already satisfied: six in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (3.19.1)\n",
      "Requirement already satisfied: promise in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.3)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from etils[epath]->tensorflow-datasets) (4.1.1)\n",
      "Requirement already satisfied: zipp in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from etils[epath]->tensorflow-datasets) (3.7.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from etils[epath]->tensorflow-datasets) (5.10.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.53.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tqdm->tensorflow-datasets) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245aa53f",
   "metadata": {},
   "source": [
    "Primero debemos descagar el set de imágenes con las que probaremos VGG16, son imágenes de distintos tipos de flores. Están en el paquete tfds y para incluirlas en el algoritmo del modelo debemos redimensionarla con resize(), y, posteriormente, convertir su información en datos categóricos con to_categorical(), una función de tensorflow. Esta función devuelve una matriz de valores binarios (ya sea '1' o '0'), tiene un número de filas igual a la longitud del vector de entrada y un número de columnas igual al número de clases. De tal manera que cada imagen seria un elemento del vector de entrada (una fila de la matriz) y quedará reflejado un 1 en la columna que corresponda con la clase a la que pertenece.\n",
    "\n",
    "https://www.geeksforgeeks.org/python-keras-keras-utils-to_categorical/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed070640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "## Loading images and labels\n",
    "(train_ds, train_labels), (test_ds, test_labels) = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:70%]\", \"train[:30%]\"], ## Train test split\n",
    "    batch_size=-1,\n",
    "    as_supervised=True,  # Include labels\n",
    ")\n",
    "\n",
    "## Resizing images\n",
    "train_ds = tf.image.resize(train_ds, (150, 150))\n",
    "test_ds = tf.image.resize(test_ds, (150, 150))\n",
    "\n",
    "## Transforming labels to correct format\n",
    "train_labels = to_categorical(train_labels, num_classes=5)\n",
    "test_labels = to_categorical(test_labels, num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9021b9",
   "metadata": {},
   "source": [
    "Después nos descargamos la red VGG16 y no cambiamos los pesos iniciales que recoge de \"imagenet\". Su estructura tiene los siguientes componentes.\n",
    "\n",
    "Input\n",
    "\n",
    "Convolution(x2)\n",
    "MaxPooling\n",
    "\n",
    "Convolution(x2)\n",
    "MaxPooling\n",
    "\n",
    "Convolution(x3)\n",
    "MaxPooling\n",
    "\n",
    "Convolution(x3)\n",
    "MaxPooling\n",
    "\n",
    "Convolution(x3)\n",
    "MaxPooling\n",
    "\n",
    "Flatten\n",
    "Dense(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b66c2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=train_ds[0].shape)\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "## Preprocessing input\n",
    "train_ds = preprocess_input(train_ds) \n",
    "test_ds = preprocess_input(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb9f602",
   "metadata": {},
   "source": [
    "Aquí queda mejor resumido el contenido de VGG16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "625278c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67626b22",
   "metadata": {},
   "source": [
    "Las últimas capas para clasificar estas flores en concreto debemos adaptarlas a nuestro caso particular. Por eso debemos definir las capas densas y una última capa de predicción. En la variable \"model\" queda almacenado el modelo VGG16 básico junto con estas últimas capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5294702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer_1 = layers.Dense(50, activation='relu')\n",
    "dense_layer_2 = layers.Dense(20, activation='relu')\n",
    "prediction_layer = layers.Dense(5, activation='softmax')\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense_layer_1,\n",
    "    dense_layer_2,\n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b8b8c8",
   "metadata": {},
   "source": [
    "Ya podemos compilar el modelo y entrenarlo con nuestros datos de interés, que se encuentran en train_ds y train_labels. Utilizamos el fit() junto con EarlyStopping para que no se ejecuten todas las iteraciones marcadas en caso de la métrica ya no pueda mejorar más.\n",
    "\n",
    "https://keras.io/api/callbacks/early_stopping/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bec88d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "65/65 [==============================] - 100s 2s/step - loss: 1.7899 - accuracy: 0.4813 - val_loss: 1.1998 - val_accuracy: 0.5389\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 96s 1s/step - loss: 0.9098 - accuracy: 0.7012 - val_loss: 1.2066 - val_accuracy: 0.5311\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 97s 2s/step - loss: 0.6878 - accuracy: 0.7655 - val_loss: 1.0042 - val_accuracy: 0.6712\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.4897 - accuracy: 0.8190 - val_loss: 1.0202 - val_accuracy: 0.7004\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 98s 2s/step - loss: 0.3492 - accuracy: 0.8720 - val_loss: 1.0528 - val_accuracy: 0.7004\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 99s 2s/step - loss: 0.2521 - accuracy: 0.9022 - val_loss: 1.2829 - val_accuracy: 0.6809\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 104s 2s/step - loss: 0.2048 - accuracy: 0.9236 - val_loss: 1.3340 - val_accuracy: 0.6770\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.1668 - accuracy: 0.9343 - val_loss: 1.2898 - val_accuracy: 0.7043\n",
      "Epoch 9/50\n",
      "65/65 [==============================] - 96s 1s/step - loss: 0.1335 - accuracy: 0.9528 - val_loss: 1.3688 - val_accuracy: 0.7082\n",
      "Epoch 10/50\n",
      "65/65 [==============================] - 91s 1s/step - loss: 0.1307 - accuracy: 0.9528 - val_loss: 1.6204 - val_accuracy: 0.7082\n",
      "Epoch 11/50\n",
      "65/65 [==============================] - 90s 1s/step - loss: 0.0959 - accuracy: 0.9640 - val_loss: 1.3645 - val_accuracy: 0.7082\n",
      "Epoch 12/50\n",
      "65/65 [==============================] - 90s 1s/step - loss: 0.0707 - accuracy: 0.9771 - val_loss: 1.4691 - val_accuracy: 0.7160\n",
      "Epoch 13/50\n",
      "65/65 [==============================] - 91s 1s/step - loss: 0.0639 - accuracy: 0.9757 - val_loss: 1.3684 - val_accuracy: 0.7140\n",
      "Epoch 14/50\n",
      "65/65 [==============================] - 90s 1s/step - loss: 0.0527 - accuracy: 0.9800 - val_loss: 1.4814 - val_accuracy: 0.7043\n",
      "Epoch 15/50\n",
      "65/65 [==============================] - 90s 1s/step - loss: 0.0473 - accuracy: 0.9820 - val_loss: 1.6460 - val_accuracy: 0.7062\n",
      "Epoch 16/50\n",
      "65/65 [==============================] - 90s 1s/step - loss: 0.0446 - accuracy: 0.9839 - val_loss: 1.5233 - val_accuracy: 0.6984\n",
      "Epoch 17/50\n",
      "65/65 [==============================] - 90s 1s/step - loss: 0.0480 - accuracy: 0.9830 - val_loss: 1.5841 - val_accuracy: 0.7218\n",
      "Epoch 18/50\n",
      "65/65 [==============================] - 90s 1s/step - loss: 0.0458 - accuracy: 0.9854 - val_loss: 1.6690 - val_accuracy: 0.7004\n",
      "Epoch 19/50\n",
      "65/65 [==============================] - 91s 1s/step - loss: 0.0433 - accuracy: 0.9839 - val_loss: 1.6735 - val_accuracy: 0.7179\n",
      "Epoch 20/50\n",
      "65/65 [==============================] - 90s 1s/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 1.6850 - val_accuracy: 0.7179\n",
      "Epoch 21/50\n",
      "65/65 [==============================] - 90s 1s/step - loss: 0.0296 - accuracy: 0.9908 - val_loss: 1.7082 - val_accuracy: 0.7179\n",
      "Epoch 22/50\n",
      "65/65 [==============================] - 90s 1s/step - loss: 0.0213 - accuracy: 0.9912 - val_loss: 1.8468 - val_accuracy: 0.7198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db0f30e490>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
    "\n",
    "model.fit(train_ds, train_labels, epochs=50, validation_split=0.2, batch_size=32, callbacks=[es])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
