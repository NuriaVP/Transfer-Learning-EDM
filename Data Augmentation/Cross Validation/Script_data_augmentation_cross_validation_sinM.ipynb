{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08257b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report  \n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_VGG16\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as preprocess_VGG19\n",
    "\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input as preprocess_Xception\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as preprocess_ResNet50V2\n",
    "\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as preprocess_ResNet101_152\n",
    "\n",
    "from tensorflow.keras.applications import ResNet152\n",
    "\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_InceptionV3\n",
    "\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input as preprocess_InceptionResNetV2\n",
    "\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as preprocess_MobileNet\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as preprocess_DenseNet121\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as preprocess_DenseNet201\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfe6dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct(proc):\n",
    "    if (proc==False):\n",
    "        directorio = 'Datos cross validation base sM EMD'\n",
    "    else:\n",
    "        directorio = 'Datos Cross Validation sM EMD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3807227",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 'rgb' \n",
    "batch = 16\n",
    "dic_escala = {VGG16:224,VGG19:224,Xception:299,ResNet50V2:224,ResNet101:224,ResNet152:224,InceptionResNetV2:299,MobileNet:224,DenseNet121:224,DenseNet201:224,EfficientNetB0:224,InceptionV3:299}\n",
    "dic_preprocesado = {VGG16:preprocess_VGG16,\n",
    "                VGG19:preprocess_VGG19,\n",
    "                Xception:preprocess_Xception,\n",
    "                ResNet50V2:preprocess_ResNet50V2,\n",
    "                ResNet101:preprocess_ResNet101_152,\n",
    "                ResNet152:preprocess_ResNet101_152,\n",
    "                InceptionResNetV2:preprocess_InceptionResNetV2,\n",
    "                MobileNet:preprocess_MobileNet,\n",
    "                DenseNet121:preprocess_DenseNet121,\n",
    "                DenseNet201:preprocess_DenseNet201,\n",
    "                EfficientNetB0:preprocess_EfficientNetB0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d5cf8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_gen(gens):\n",
    "    while True:\n",
    "        tuplas = []\n",
    "        for i in gens:\n",
    "            tuplas.append(next(i))\n",
    "        arrays_images = []\n",
    "        arrays_labels = []\n",
    "        for i in tuplas:\n",
    "            arrays_images.append(i[0])\n",
    "            arrays_labels.append(i[1])\n",
    "        images = np.concatenate(arrays_images)\n",
    "        labels = np.concatenate(arrays_labels)\n",
    "\n",
    "        yield(tuple((images,labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f034cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num(directorio,K_test,K_val):\n",
    "    total = 0\n",
    "    lista_K = ['K1','K2','K3','K4','K5']\n",
    "    lista_K.remove(K_test)\n",
    "    lista_K.remove(K_val)\n",
    "    for K in lista_K:\n",
    "            for origen in ['MESSIDOR','iPhone','OCT','Samsung']:\n",
    "                for grado in ['EMD', 'NO EMD']:\n",
    "                    total += len(os.listdir(directorio + '/' + K + '/' + origen + '/' + grado + '/' + grado + '/'))\n",
    "\n",
    "    num_train = int(total*0.8)\n",
    "    num_val = int(total*0.2)\n",
    "    return num_train,num_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generador_train(modelo,directorio,K,origen,grado,escala):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function = preprocesado[modelo],\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        zca_whitening=True,\n",
    "        zca_epsilon=1e-06\n",
    "        preprocessing_function = dic_preprocesado[modelo]\n",
    "    )\n",
    "    generator = train_datagen.flow_from_directory(\n",
    "        directory = directorio + '/' + K + '/' + origen + '/' + grado,\n",
    "        target_size = (escala,escala),\n",
    "        color_mode = color,\n",
    "        class_mode='categorical',\n",
    "        batch_size = 1,\n",
    "        seed = 42\n",
    "    )  \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen(directorio,K_test,K_val,escala=224):\n",
    "    lista_K = ['K1','K2','K3','K4','K5']\n",
    "    lista_K.remove(K_test)\n",
    "    lista_K.remove(K_val)\n",
    "    generadores = []\n",
    "    for K in lista_K:\n",
    "        for origen in ['iPhone','OCT','Samsung']:\n",
    "            for grado in ['EMD', 'NO EMD']:\n",
    "                generadores.append(generador_train(directorio,K,origen,grado,escala))\n",
    "                \n",
    "    generador_combinado = combine_gen(generadores)\n",
    "    return generador_combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6ab9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generador_val(modelo,directorio,K_val,escala):\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        preprocessing_function = dic_preprocesado[modelo]\n",
    "    )\n",
    "    generator = train_datagen.flow_from_directory(\n",
    "        directory = directorio + '/' + K_val,\n",
    "        target_size = (escala,escala),\n",
    "        color_mode = color,\n",
    "        class_mode='categorical',\n",
    "        batch_size = 1,#vamos a equilibrar proporciones, 1/80 ya que tenemos 4 cajas de train * 4 orígenes * 5 grados\n",
    "        seed = 42\n",
    "    )\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d9df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_learning(directorio,K_test,red):\n",
    "    if (K_test == 'K1'):\n",
    "        K_val = 'K5'\n",
    "    elif (K_test == 'K2'):\n",
    "        K_val = 'K1'\n",
    "    elif (K_test == 'K3'):\n",
    "        K_val = 'K2'\n",
    "    elif (K_test == 'K4'):\n",
    "        K_val = 'K3'\n",
    "    elif (K_test == 'K5'):\n",
    "        K_val = 'K4'\n",
    "   \n",
    "    train_generator = train_gen(red,directorio,K_test,K_val,escala = dic_escala[red])\n",
    "    val_generator = generador_val(red,directorio,K_val,escala = dic_escala[red])\n",
    "    \n",
    "    #para el generador de tipo test debemos definir antes un nuevo ImageDataGenerator\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=dic_preprocesado[red])\n",
    "    \n",
    "    #definimos un generador para Samsung, que coja únicamente las imágenes de Samsung de la caja de test\n",
    "    test_Samsung = test_datagen.flow_from_directory(\n",
    "        directory = directorio + '/' + K_test + '/Samsung/',\n",
    "        target_size = (dic_escala[red],dic_escala[red]),\n",
    "        color_mode = color,\n",
    "        shuffle = False,\n",
    "        class_mode='categorical',\n",
    "        batch_size=1,\n",
    "        seed = 42\n",
    "    )\n",
    "    \n",
    "    #y lo mismo para iPhone, que solo coja las imágenes de iPhone de la caja de test\n",
    "    test_iPhone = test_datagen.flow_from_directory(\n",
    "        directory = directorio + '/' + K_test + '/iPhone/',\n",
    "        target_size = (dic_escala[red],dic_escala[red]),\n",
    "        color_mode = color,\n",
    "        shuffle = False,\n",
    "        class_mode='categorical',\n",
    "        batch_size=1,\n",
    "        seed = 42\n",
    "    )\n",
    "    \n",
    "    #Definimos el modelo base de transfer-learning\n",
    "    base_model = red(weights=None, include_top=False, input_shape=(dic_escala[red],dic_escala[red],3))\n",
    "    base_model.load_weights('Pesos/' + str(red).split(' ')[1] + '.h5')\n",
    "    base_model.trainable = False ## Not trainable weights\n",
    "    \n",
    "    #Definir fine tunning\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer_1 = layers.Dense(1024, activation='relu')\n",
    "    dense_layer_2 = layers.Dense(512, activation='relu')\n",
    "    prediction_layer = layers.Dense(2, activation='softmax')\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer_1,\n",
    "        dense_layer_2,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    \n",
    "    #no usaremos compensador de pesos ya que las proporciones entre grados y entre dispositivos están comepnsadas\n",
    "    \n",
    "    #Entrenar el modelo\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', patience=20,  restore_best_weights=True)\n",
    "\n",
    "    #ahora el .fit acepta también generators como x\n",
    "    history = model.fit(\n",
    "        x = train_generator,\n",
    "        batch_size=batch,\n",
    "        epochs=200,\n",
    "        steps_per_epoch = math.ceil(num(directorio,K_test,K_val) / batch),\n",
    "        callbacks=[es],\n",
    "        validation_data = val_generator,\n",
    "        validation_steps = math.ceil(num(directorio,K_test,K_val) / batch)\n",
    "    )\n",
    "    \n",
    "    #Métricas de evaluación\n",
    "    print('_________________________________________________________________________')\n",
    "    print(f'MÉTRICAS DE EVALUACIÓN\\n *CrossValidation\\n *Balanced Generator\\n *Red: {red}\\n *K_test: {K_test}')\n",
    "    print('_________________________________________________________________________')\n",
    "    \n",
    "    print('___________________________________________________________________________________')\n",
    "    print('TEST: iPHONE')\n",
    "    print('___________________________________________________________________________________')\n",
    "    score_test_iphone = model.evaluate(x = test_iPhone, verbose = 0)\n",
    "    print(\"Test loss:\", score_test_iphone[0])\n",
    "    print(\"Test accuracy:\", score_test_iphone[1])\n",
    "    \n",
    "    y_test_iphone = test_iPhone.classes\n",
    "    \n",
    "    predictions_iphone = model.predict(test_iPhone)\n",
    "    y_pred_iphone = list(map(lambda x: list(x).index(max(x)),predictions_iphone))\n",
    "\n",
    "    matrix_iphone = confusion_matrix(y_test_iphone, y_pred_iphone)\n",
    "    print(f\"Matriz de confusión en test con iPhone:\\n\\n{matrix_iphone}\\n\")\n",
    "    \n",
    "    f_score_iphone = f1_score(y_true = y_test_iphone, y_pred = y_pred_iphone, average = 'weighted')\n",
    "    print(f\"Valor de 'F1 score' en test con iPhone: {f_score_iphone}\\n\")\n",
    "    \n",
    "    auc_roc_iphone = roc_auc_score(y_test_iphone, y_pred_iphone, multi_class = 'ovo')\n",
    "    print(f\"Valor de 'AUC' en test con iPhone: {auc_roc_iphone}\\n\")\n",
    "    \n",
    "    print('___________________________________________________________________________________')\n",
    "    print('TEST: Samsung')\n",
    "    print('___________________________________________________________________________________')\n",
    "    \n",
    "    score_test_samsung = model.evaluate(x = test_Samsung, verbose = 0)\n",
    "    print(\"Test loss:\", score_test_samsung[0])\n",
    "    print(\"Test accuracy:\", score_test_samsung[1])\n",
    "    \n",
    "    y_test_samsung = test_Samsung.classes\n",
    "    \n",
    "    predictions_samsung = model.predict(test_Samsung)\n",
    "    y_pred_samsung = list(map(lambda x: list(x).index(max(x)),predictions_samsung))\n",
    "\n",
    "    matrix_samsung = confusion_matrix(y_test_samsung, y_pred_samsung)\n",
    "    print(f\"Matriz de confusión en test con samsung:\\n\\n{matrix_samsung}\\n\")\n",
    "    \n",
    "    f_score_samsung = f1_score(y_true = y_test_samsung, y_pred = y_pred_samsung, average = 'weighted')\n",
    "    print(f\"Valor de 'F1 score' en test con samsung: {f_score_samsung}\\n\")\n",
    "    \n",
    "    auc_roc_samsung = roc_auc_score(y_test_samsung, y_pred_samsung, multi_class = 'ovo')\n",
    "    print(f\"Valor de 'AUC' en test con Samsung: {auc_roc_samsung}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = sys.argv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRUEBA Sin proc\n",
    "proc=False\n",
    "for K_test in ['K1', 'K2', 'K3', 'K4', 'K5']:\n",
    "    directorio = direct(proc)\n",
    "    transfer_learning(directorio,K_test,modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbefdb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRUEBA Con proc\n",
    "proc=False\n",
    "for K_test in ['K1', 'K2', 'K3', 'K4', 'K5']:\n",
    "    directorio = direct(proc)\n",
    "    transfer_learning(directorio,K_test,modelo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
