{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d45f41f",
   "metadata": {},
   "source": [
    "# PRUEBA VGG16 CON CIFAR100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b13c7a7",
   "metadata": {},
   "source": [
    "02/01/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1e7fc1",
   "metadata": {},
   "source": [
    "https://www.enmilocalfunciona.io/deep-learning-basico-con-keras-parte-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b875e041",
   "metadata": {},
   "source": [
    "Aspecto datasets CIFAR100 para imitarlo con mis datos:\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ef358",
   "metadata": {},
   "source": [
    "**Importando librer√≠as necesarias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c93edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import misc  \n",
    "from PIL import Image  \n",
    "import glob  \n",
    "import matplotlib.pyplot as plt  \n",
    "import scipy.misc  \n",
    "from matplotlib.pyplot import imshow  \n",
    "%matplotlib inline\n",
    "from IPython.display import SVG  \n",
    "import cv2  \n",
    "import seaborn as sn  \n",
    "import pandas as pd  \n",
    "import pickle  \n",
    "from keras import layers  \n",
    "from keras.layers import Flatten, Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout  \n",
    "from keras.models import Sequential, Model, load_model  \n",
    "from keras.preprocessing import image  \n",
    "from tensorflow.keras.utils import load_img  \n",
    "from tensorflow.keras.utils import img_to_array  \n",
    "from keras.applications.imagenet_utils import decode_predictions  \n",
    "from keras.utils import layer_utils, np_utils  \n",
    "from keras.utils.data_utils import get_file  \n",
    "from keras.applications.imagenet_utils import preprocess_input  \n",
    "from keras.utils.vis_utils import model_to_dot  \n",
    "from keras.utils import plot_model  \n",
    "from keras.initializers import glorot_uniform  \n",
    "from keras import losses  \n",
    "import keras.backend as K  \n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from sklearn.metrics import confusion_matrix, classification_report  \n",
    "import tensorflow as tf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2325dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "\n",
    "(x_train_original, y_train_original), (x_test_original, y_test_original) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600e7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train_original, 100)\n",
    "y_test = np_utils.to_categorical(y_test_original, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6ebeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_data(data):  \n",
    "    data_upscaled = np.zeros((data.shape[0], 48, 48, 3))\n",
    "    for i, img in enumerate(data):\n",
    "        large_img = cv2.resize(img, dsize=(48, 48), interpolation=cv2.INTER_CUBIC)\n",
    "        data_upscaled[i] = large_img\n",
    "\n",
    "    return data_upscaled\n",
    "\n",
    "x_train_resized = resize_data(x_train_original)  \n",
    "x_test_resized = resize_data(x_test_original)  \n",
    "x_train_resized = x_train_resized / 255  \n",
    "x_test_resized = x_test_resized / 255  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee253987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "\n",
    "def create_vgg16():  \n",
    "    model = vgg16.VGG16(include_top=True, weights=None, input_tensor=None, input_shape=(48,48,3), pooling=None, classes=100)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9370a35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = create_vgg16()  \n",
    "vgg16_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc', 'mse'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "824ca1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              2101248   \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 100)               409700    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,006,948\n",
      "Trainable params: 34,006,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598fe342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1563/1563 [==============================] - 1355s 866ms/step - loss: 4.6053 - acc: 0.0095 - mse: 0.0099 - val_loss: 4.6051 - val_acc: 0.0100 - val_mse: 0.0099\n",
      "Epoch 2/2\n",
      "1563/1563 [==============================] - 1292s 827ms/step - loss: 4.6053 - acc: 0.0096 - mse: 0.0099 - val_loss: 4.6050 - val_acc: 0.0157 - val_mse: 0.0099\n"
     ]
    }
   ],
   "source": [
    "vgg16 = vgg16_model.fit(x=x_train_resized, y=y_train, batch_size=32, epochs=2, verbose=1, validation_data=(x_test_resized, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf50ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
